{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Network\n",
    "In Order to make decision in a continuous action space, we shifted from multi-head DQN to policy Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in Network Setting\n",
    "Network code exactly like before; except last layer no longer output 11 heads but only 1 head as mean leverage, variance of leverage is manually set and then actions are drown as normal distribution. loss is therefore no longer l2 loss but rather standard loss of vanilla policy network, a product of reward and -loglikelihood. i.e only thing changed in NN code are last 2 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, Activation = 'Sigmoid', layers = [20, 10]):\n",
    "        self._Activation_Method = Activation\n",
    "        self._Weights = None\n",
    "        self._Weight_Shape = layers\n",
    "        \n",
    "    def fit(self, X, Y, Loss, learn_rate = 0.001, Epoch = 50, **kwarg):\n",
    "        if isinstance(X, list):\n",
    "            Input_shape = len(X[0])\n",
    "            X = np.array(X)\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            Input_shape = X.shape[1]\n",
    "        if isinstance(Y, list):\n",
    "            Y = np.array(Y).reshape(-1,1)\n",
    "            \n",
    "        if self._Weights is None:\n",
    "            ##Create the weights by initialising them as random values\n",
    "            previous = Input_shape\n",
    "            for Layer_Size in self._Weight_Shape:\n",
    "                if self._Weights is None:\n",
    "                    self._Weights = [np.random.rand(previous, Layer_Size)/((previous + Layer_Size)**0.5)]\n",
    "                else:\n",
    "                    Current_Layer = np.random.rand(previous, Layer_Size)/((previous + Layer_Size)**0.5)\n",
    "                    self._Weights.append(Current_Layer)\n",
    "                previous = Layer_Size\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        for i in range(Epoch):\n",
    "            ##Forward Propogation and record useful informations\n",
    "            H_Collect = [X]\n",
    "            A_Collect = []\n",
    "            Derivative_Collect = []\n",
    "            for idx, Weights in enumerate(self._Weights):\n",
    "                if idx != len(self._Weights)-1:\n",
    "                    Layer_Active = self._Activation_Method\n",
    "                else:\n",
    "                    Layer_Active = 'Identity'\n",
    "\n",
    "                A = np.matmul(H_Collect[idx], Weights)\n",
    "                H, derivative = self._Activation(A, how = Layer_Active)\n",
    "                H_Collect.append(H)\n",
    "                A_Collect.append(A)\n",
    "                Derivative_Collect.append(derivative)\n",
    "\n",
    "            ##Backward Propogation to calculate updated weights\n",
    "            dW_Collect = []\n",
    "            dA_Collect = []\n",
    "            dH_Collect = []\n",
    "            for idx, Hidden in enumerate(H_Collect[::-1]):\n",
    "                if idx==0:\n",
    "                    D_Yhat = self._Loss_Transform(Method = Loss, Y=Y, Y_hat= Hidden, **kwarg)\n",
    "                    dH_Collect.append(D_Yhat)\n",
    "                    continue\n",
    "                else:\n",
    "                    dA = dH_Collect[-1] * Derivative_Collect[::-1][idx-1]\n",
    "                    dW = np.matmul(Hidden.transpose(), dA)\n",
    "                    dH = np.matmul(dA, self._Weights[::-1][idx-1].transpose())\n",
    "                    dA_Collect.append(dA)\n",
    "                    dW_Collect.append(dW)\n",
    "                    dH_Collect.append(dH)\n",
    "\n",
    "            for i in range(len(self._Weights)):\n",
    "                self._Weights[i] -= learn_rate * dW_Collect[::-1][i]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self._Weights is None:\n",
    "            print('Please fit your model before you use them to predict')\n",
    "        else:\n",
    "            Predictions = X\n",
    "            for idx, Weights in enumerate(self._Weights):\n",
    "                if idx != len(self._Weights) - 1:\n",
    "                    Layer_Active = self._Activation_Method\n",
    "                else:\n",
    "                    Layer_Active = 'Identity'\n",
    "                Predictions = np.matmul(Predictions, Weights)\n",
    "                Predictions, _ = self._Activation(Predictions, how = Layer_Active)\n",
    "        return Predictions\n",
    "    \n",
    "    def _Activation(self,x, how):\n",
    "        if how == 'Sigmoid':\n",
    "            outcome = np.exp(x)/(1 + np.exp(x))\n",
    "            derivative = outcome*(1-outcome)\n",
    "        elif how == 'Relu':\n",
    "            outcome = x*(x>0)\n",
    "            derivative = np.sign(outcome) \n",
    "        elif how == 'Identity':\n",
    "            outcome = x\n",
    "            derivative = 1\n",
    "        elif how == 'Tanh':\n",
    "            outcome = 2/(1+np.exp(-2*x)) - 1\n",
    "            derivative = 1- outcome**2\n",
    "        elif how == 'Softplus':\n",
    "            outcome = np.log(1+np.exp(x))\n",
    "            derivative = 1/(1+np.exp(-x))\n",
    "        return outcome, derivative\n",
    "\n",
    "    def _Loss_Transform(self, Y, Y_hat, Method, Z = None, sigma_sq = None, reward = None):\n",
    "        if Method == 'Onehot':\n",
    "            #Check Z is in correct form and prepare it for Back Prop\n",
    "            if Z is None:\n",
    "                print('For One hot loss method you need to provide Z!!')\n",
    "            elif isinstance(Z, np.ndarray) == False:\n",
    "                try:\n",
    "                    Z = np.array(Z)\n",
    "                except:\n",
    "                    print('Z is in an unaccepted form, please Check')        \n",
    "            if Z.shape[0] != Y.shape[0]:\n",
    "                Z = Z.transpose()\n",
    "            #Calculate the Last Layer Back Prop\n",
    "            Loss = np.zeros(shape = Z.shape)\n",
    "            for i in range(Z.shape[0]):\n",
    "                Loss[i, :] = Y[i] * Z[i, :]\n",
    "            Loss = 2 * (Y_hat*Z - Loss)\n",
    "        \n",
    "        if Method == 'Ordinary':\n",
    "            Loss = 2*(Y_hat - Y)\n",
    "        \n",
    "        if Method == 'Gaussian':\n",
    "            Loss = (Y_hat - Y)*reward/sigma_sq\n",
    "        \n",
    "        return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup required for Merton Model\n",
    "# annual calibration\n",
    "mu = 0.07\n",
    "sigma = 0.16\n",
    "rf = 0.01\n",
    "\n",
    "# static one month investment\n",
    "dt      = 1/12\n",
    "horizon = 1/12 \n",
    "n_steps = int(horizon / dt)\n",
    "\n",
    "# return generator\n",
    "def GBM_Return ():\n",
    "    # Generate returns from a log normal distribution\n",
    "    Mean = (mu - (sigma ** 2) / 2) * dt\n",
    "    Std = sigma * (dt ** 0.5)\n",
    "    Return = np.random.normal(Mean, Std, 1)[0]\n",
    "\n",
    "    return np.exp(Return)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Set up\n",
    "This is most simplified version where we use random number as input and terminate in 1 step,without experience replay. This model is trained over 200,000 episodes, refit every episode with standard deviation gradually decay from sqrt(2) to 0.1 within 100,000 episodes. This code takes about 10 seconds to run\n",
    "\n",
    "Decreasing the variance to very small will destabilise the mean given the gradient where numeritor grow linearly and denominator grow quadratically\n",
    "Loss = (Y_hat - Y)*reward/sigma_sq\n",
    "\n",
    "To tackle this problem we adopted a gradually decreasing learning rate that drop from 0.01 to 0.001 to 0.0001 as the variance decreases\n",
    "\n",
    "Also instead of using crude reward, we used advantage to calculate the loss, advantage = (current reward - average reward of this step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976edb492dbe4ef1a749209ea7cd2732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1e434d5ee80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Policy Model Setting\n",
    "Layers = [5,5,1]\n",
    "PNetwork = NN(Activation= 'Sigmoid', layers= Layers)\n",
    "refit = 1\n",
    "\n",
    "# Episode Settings\n",
    "n_episodes    = int(2e5)\n",
    "Sigmasq_range = [2, 0.01]\n",
    "Anneal        = n_episodes\n",
    "s_dim         = 1\n",
    "exp = []\n",
    "average = [0]*n_steps\n",
    "\n",
    "# Prediction Function\n",
    "def Mu(S0):\n",
    "    if PNetwork._Weights is None:\n",
    "        output = 0\n",
    "    else:\n",
    "        output = PNetwork.predict(S0)[0][0]\n",
    "    return output\n",
    "\n",
    "#Start training\n",
    "nans = {}\n",
    "Plot_X =[]\n",
    "Plot_Y =[]\n",
    "for i in tqdm(range(n_episodes)):\n",
    "    s0 = np.ones((1,1))   # Set initial Wealth\n",
    "    if i <= Anneal:\n",
    "        Sigma_sq = Sigmasq_range[0] + i/Anneal * (Sigmasq_range[1] - Sigmasq_range[0])\n",
    "    else:\n",
    "        Sigma_sq = Sigmasq_range[1]\n",
    "    \n",
    "    if Sigma_sq > 1:\n",
    "        learn_Rate = 0.01\n",
    "    elif (Sigma_sq >0.25) and (Sigma_sq<1):\n",
    "        learn_Rate = 0.001\n",
    "    else:\n",
    "        learn_Rate = 0.0001\n",
    "        \n",
    "    # Step through to collect the (S,A,R/Adv,S') pair\n",
    "    for t in range(n_steps):\n",
    "        ep_Mu = Mu(s0)\n",
    "        leverage = np.random.normal(ep_Mu, Sigma_sq**0.5)\n",
    "        s1 = s0 * (leverage * GBM_Return() + (1 - leverage) * (1 + rf * dt))\n",
    "\n",
    "        if s1<0:\n",
    "            if round(leverage,1) not in nans:\n",
    "                nans[round(leverage,1)] = 1 # count failures of discrete time approximation for each a\n",
    "            else:\n",
    "                nans[round(leverage,1)] += 1\n",
    "            advantage = np.ones((1,1)) * (-20)\n",
    "            exp.append({'s0' : np.random.uniform(), 'a': leverage, 'r': advantage, 's1': s1})\n",
    "        \n",
    "        else:    \n",
    "            average[t] = (i*average[t] + np.log(s1))/(i+1)\n",
    "            advantage = np.log(s1) - average[t]\n",
    "            exp.append({'s0' : np.random.uniform(), 'a': leverage, 'r': advantage, 's1': s1})\n",
    "            s0 = s1\n",
    "            \n",
    "    # Refit using the most recent experiences then clear all the records\n",
    "    if len(exp)/n_steps == refit:\n",
    "        X = np.array([d['s0'] for d in exp]).reshape(-1, s_dim)\n",
    "        Y = [d['a'] for d in exp]\n",
    "        Advantage = np.array([d['r'] for d in exp]).reshape(-1,1)\n",
    "        PNetwork.fit(X, Y, Epoch =1, learn_rate = learn_Rate, Loss = 'Gaussian', sigma_sq = Sigma_sq, reward = Advantage)\n",
    "        exp = []\n",
    "\n",
    "    if (PNetwork._Weights is not None) and (i%100 == 0):\n",
    "        Plot_X.append(i)\n",
    "        Plot_Y.append(PNetwork.predict(s0))\n",
    "    \n",
    "    \n",
    "Plot_Y = [y[0][0] for y in Plot_Y]\n",
    "plt.plot(Plot_X, Plot_Y)\n",
    "plt.hlines((mu - rf) / (sigma**2), xmin= 0, xmax= n_episodes, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
